# -*- coding: utf-8 -*-
'''
 * @Author: Yu Zitong
 * @Date: 2018-03-24 13:40:15
 * @Last Modified by:   Yu Zitong
 * @Last Modified time: 2018-03-24 13:40:15
 * prediction of tumours classification with DNA methylation data, using trained model.
 * input: ./data_src/*.txt
 *        downloaded from TCGA
 * output: 1. pretreated data in ./pretreated_src. Format: .csv
 *         2. the predictions of input DNA methylation files
'''
# pylint: disable=invalid-name
# pylint: disable=line-too-long

from __future__ import division
import os
import glob
import sys
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import SGD
import numpy as np

def input_data_pretreat(src, CpgSet):
    '''
    pretreat input
    input: 1. DNA methylation data path directly downloaded from TCGA
           2. cpg site list
    output: 1. pretreated data in ./pretreated_src/. Format: .csv
            2. pretreated data path list
    '''
    f_no = 0
    num = 0
    total = len(src)
    pre_data = []
    for item in src:
        num += 1
        with open(item) as per:
            cpg_meth_bv = []
            for line in per:
                if line.find('Beta_value') != -1:
                    continue
                else:
                    cpgid = line.rstrip('\n').split('\t')[0]
                    bv = line.rstrip('\n').split('\t')[1]
                    if bv == 'NA':
                        bv = '00.0'
                    if cpgid in CpgSet:
                        cpg_meth_bv.append(bv)
            datapath = pretreated_src + '/' + 'pretreated_'+ '-'.join(item.split('.')[-3].split('-')[0:3]) + '_' + str(num) +'.csv'
            pre_data.append(datapath)
            with open(datapath, 'w') as pretreated:
                bvs = '\n'.join(cpg_meth_bv)
                pretreated.write(bvs + '\n')
            f_no += 1
            sys.stdout.write('\r[' + int(float(f_no/total) * 150) * '=' + int(float((total - f_no)/total) * 150) * ' ' + ']' + str(round(float(f_no/total)*100, 2)) + '%')
    return pre_data

def get_cpg_site(cpgsite):
    '''
    return cpg site set
    input: cpg list file
    output: cpg_set
    '''
    cpgset = set()
    with open(cpgsite) as cpg:
        for line in cpg:
            cpgset.add(line.rstrip('\n'))
    return cpgset

def get_bv(src):
    '''
    read beta value from ./data/DNA_meth_pretreated/*
    input: .csv files(e.g. BRCA_report_TCGA-BH-A0BQ_452.csv)
    output: a list of beta value
    '''
    with open(src) as f:
        bv = f.readlines()
    for i, v in enumerate(bv):
        bv[i] = float(v.rstrip('\n'))
    return bv

def input_data(file_list):
    '''
    get input data for network training
    input: file list
    output: an array of data for training
    '''
    print 'Preparing input data...'
    print 'It may takes little time. Please be patient.'
    dd = []
    i = 0
    num = len(file_list)
    for item in file_list:
        dd.append(get_bv(item))
        i += 1
        sys.stdout.write('\r[' + int(float(i/num) * 150) * '#' + int(float((num - i)/num) * 150) * ' ' + ']' + str(round(float(i/num)*100, 2)) + '%')
    d = np.array(dd)
    return d

def build_model(dim0, dim1, dim2, dim3, dropout_rate):
    '''
    build and compile network model
    input:
        dim0: input shape
        dim1: first layer unit
        dim2: second layer unit
        dim3: label number
        dropout rate: drop dropout_rate% input units
    output: model
    '''
    model = Sequential()
    model.add(Dense(dim1, activation='relu', input_shape=(dim0,)))
    # Dropout  to prevent neural networks from overfitting
    model.add(Dropout(dropout_rate))
    model.add(Dense(dim2, activation='relu'))
    model.add(Dropout(dropout_rate))
    model.add(Dense(dim3, activation='softmax'))
    model.summary()
    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    model.compile(loss='categorical_crossentropy',
                  optimizer=sgd,
                  metrics=['accuracy'])
    return model

def prediction(txt, pre, dis):
    '''
    print prediction result
    input: 1. file path
           2. numpy or numpy array generated by model.predict()
           3. disease list
    output: print prediction results
    '''
    t = 0
    for rst in pre:
        i = np.argmax(rst)
        print txt[t] + ':\t'+ dis[i]
        t += 1

def disease_list(dis):
    '''
    get disease list
    input: disease list file path
    output: disease list
    '''
    disl = []
    with open(dis) as d:
        for line in d:
            disl.append(line.rstrip('\n'))
    return disl

if __name__ == '__main__':

    data_src = './data/'
    txt_list = glob.glob(data_src + '*8.txt')
    pretreated_src = './data/DNA_meth_pre_test/'
    os.system('mkdir ' + pretreated_src)

    cpg_list = get_cpg_site('cpg_list')

    # input data pretreating
    csv_list = input_data_pretreat(txt_list, cpg_list)

    data = input_data(csv_list)

    meth_model = build_model(25978, 2000, 128, 18, 0.2)
    # load the trained model
    meth_model.load_weights('meth_weights.h5')

    # predict the results
    pred = meth_model.predict(data)

    disease_type = disease_list('dis_list')
    disease_type.append('Normal')

    # result output
    prediction(txt_list, pred, disease_type)
